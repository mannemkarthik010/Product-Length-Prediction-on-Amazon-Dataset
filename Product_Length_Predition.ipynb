{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAfrQ2z1i4uw"
      },
      "source": [
        "# Product Length Prediction on Amazon Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaXFwsCxhOJW",
        "outputId": "5c342a8e-2965-4c4f-cbbf-45dd7d72cfc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on:\", DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sh56G3cCjIrO"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(421)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m09U41FwjPUO"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "We will:\n",
        "\n",
        "- Merge text fields into one input string  \n",
        "- Map product-type IDs to embedding indices  \n",
        "- Log-transform & standardize target values  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WSTaYrvJjMx5"
      },
      "outputs": [],
      "source": [
        "def build_type_mapping(df: pd.DataFrame, min_count: int = 10):\n",
        "    counts = df[\"PRODUCT_TYPE_ID\"].value_counts()\n",
        "    id_to_index = {}\n",
        "    current = 0\n",
        "\n",
        "    for raw_id, cnt in counts.items():\n",
        "        if cnt >= min_count:\n",
        "            id_to_index[int(raw_id)] = current\n",
        "            current += 1\n",
        "\n",
        "    default_index = current\n",
        "    return id_to_index, default_index\n",
        "\n",
        "\n",
        "def compute_target_stats(df: pd.DataFrame, clip: float = 12.0):\n",
        "    lengths = df[\"PRODUCT_LENGTH\"].astype(float).values\n",
        "    log_lengths = np.log(np.clip(lengths, 1e-6, None))\n",
        "    log_lengths = np.clip(log_lengths, None, clip)\n",
        "    mean = float(log_lengths.mean())\n",
        "    std = float(log_lengths.std())\n",
        "    return mean, std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b7P_kd8ljTjS"
      },
      "outputs": [],
      "source": [
        "class ProductLengthDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, df, id_to_index, default_index,\n",
        "        mean, std, is_test=False, transform_target=True\n",
        "    ):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.id_to_index = id_to_index\n",
        "        self.default_index = default_index\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.is_test = is_test\n",
        "        self.transform_target = transform_target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def map_type(self, type_id):\n",
        "        # Safely handle missing or weird values\n",
        "        import pandas as pd\n",
        "\n",
        "        if pd.isna(type_id):\n",
        "            return self.default_index\n",
        "\n",
        "        try:\n",
        "            type_id_int = int(type_id)\n",
        "        except (ValueError, TypeError):\n",
        "            return self.default_index\n",
        "\n",
        "        return self.id_to_index.get(type_id_int, self.default_index)\n",
        "\n",
        "    def concat_text(self, row):\n",
        "        t = str(row.get(\"TITLE\", \"\"))\n",
        "        bp = str(row.get(\"BULLET_POINTS\", \"\"))\n",
        "        desc = str(row.get(\"DESCRIPTION\", \"\"))\n",
        "        return f\"Title: {t}, Bullet Points: {bp}, Description: {desc}\"\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        text = self.concat_text(row)\n",
        "        cat = self.map_type(row[\"PRODUCT_TYPE_ID\"])\n",
        "\n",
        "        if self.is_test:\n",
        "            return {\"text\": text, \"cat_id\": torch.tensor(cat), \"product_id\": row.get(\"PRODUCT_ID\")}\n",
        "\n",
        "        y = float(row[\"PRODUCT_LENGTH\"])\n",
        "        if self.transform_target:\n",
        "            y = math.log(max(y, 1e-6))\n",
        "            y = (y - self.mean) / self.std\n",
        "\n",
        "        return {\n",
        "            \"text\": text,\n",
        "            \"cat_id\": torch.tensor(cat),\n",
        "            \"y\": torch.tensor(y, dtype=torch.float32)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Yvl88INjw2h"
      },
      "source": [
        "## Model Architecture\n",
        "\n",
        "- Transformer encoder (BERT / RoBERTa)\n",
        "- Category embedding (32d)\n",
        "- MLP regressor  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NYKnlJ9-jVEK"
      },
      "outputs": [],
      "source": [
        "class MLPRegressor(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=256, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.BatchNorm1d(hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x).squeeze(-1)\n",
        "\n",
        "\n",
        "class TextCategoryRegressor(nn.Module):\n",
        "    def __init__(self, backbone, num_cats, cat_dim=32):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(backbone)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(backbone)\n",
        "        hidden = self.encoder.config.hidden_size\n",
        "\n",
        "        self.cat_emb = nn.Embedding(num_cats, cat_dim)\n",
        "        self.regressor = MLPRegressor(hidden + cat_dim)\n",
        "\n",
        "    def encode_text(self, texts):\n",
        "        tokens = self.tokenizer(\n",
        "            texts,\n",
        "            padding=True, truncation=True, max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        tokens = {k: v.to(DEVICE) for k, v in tokens.items()}\n",
        "        out = self.encoder(**tokens)\n",
        "        return out.last_hidden_state[:, 0, :]\n",
        "\n",
        "    def forward(self, batch):\n",
        "        text_emb = self.encode_text(batch[\"text\"])\n",
        "        cat_emb = self.cat_emb(batch[\"cat_id\"].to(DEVICE))\n",
        "        x = torch.cat([text_emb, cat_emb], dim=1)\n",
        "        return self.regressor(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6Ov8VTG9jypX"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    texts = [b[\"text\"] for b in batch]\n",
        "    cat_ids = torch.stack([b[\"cat_id\"] for b in batch])\n",
        "    output = {\"text\": texts, \"cat_id\": cat_ids}\n",
        "\n",
        "    if \"y\" in batch[0]:\n",
        "        output[\"y\"] = torch.stack([b[\"y\"] for b in batch])\n",
        "\n",
        "    if \"product_id\" in batch[0]:\n",
        "        output[\"product_id\"] = [b[\"product_id\"] for b in batch]\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_LH5fwUj1vw"
      },
      "source": [
        "## Training & Evaluation Loops\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zIOUs7Itj0F8"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, optim):\n",
        "    model.train()\n",
        "    loss_fn = nn.MSELoss()\n",
        "    losses = []\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Training\"):\n",
        "        optim.zero_grad()\n",
        "        batch = {k: v.to(DEVICE) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
        "        preds = model(batch)\n",
        "        loss = loss_fn(preds, batch[\"y\"])\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optim.step()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    return np.mean(losses)\n",
        "\n",
        "\n",
        "def evaluate(model, loader, mean, std):\n",
        "    model.eval()\n",
        "    loss_fn = nn.MSELoss()\n",
        "    mse_list, mape_sum, total = [], 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"Validation\"):\n",
        "            batch = {k: v.to(DEVICE) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
        "            preds = model(batch)\n",
        "\n",
        "            mse_list.append(loss_fn(preds, batch[\"y\"]).item())\n",
        "\n",
        "            # Convert back\n",
        "            y_true = batch[\"y\"].cpu().numpy() * std + mean\n",
        "            y_true = np.exp(y_true)\n",
        "            y_pred = preds.cpu().numpy() * std + mean\n",
        "            y_pred = np.exp(y_pred)\n",
        "\n",
        "            mape_sum += np.sum(np.abs(y_true - y_pred) / (y_true + 1e-6))\n",
        "            total += len(y_true)\n",
        "\n",
        "    return np.mean(mse_list), mape_sum / total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWkP4X24j_Gk"
      },
      "source": [
        "## Load Data, Create Split, Build Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMr35H03j3ov",
        "outputId": "3e233feb-f763-4f70-fb05-438d54a3b4fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total rows used: 60000\n",
            "Train rows: 48000  Val rows: 12000\n"
          ]
        }
      ],
      "source": [
        "TRAIN_PATH = \"train.csv\"\n",
        "\n",
        "train_full = pd.read_csv(\n",
        "    TRAIN_PATH,\n",
        "    engine=\"python\",\n",
        "    on_bad_lines=\"skip\"\n",
        ")\n",
        "\n",
        "train_full = train_full.sample(n=60000, random_state=421)\n",
        "\n",
        "val_fraction = 0.2\n",
        "val_size = int(val_fraction * len(train_full))\n",
        "\n",
        "val_df = train_full.iloc[:val_size].reset_index(drop=True)\n",
        "train_df = train_full.iloc[val_size:].reset_index(drop=True)\n",
        "\n",
        "print(\"Total rows used:\", len(train_full))\n",
        "print(\"Train rows:\", len(train_df), \" Val rows:\", len(val_df))\n",
        "\n",
        "id_to_index, default_idx = build_type_mapping(train_df)\n",
        "mean, std = compute_target_stats(train_df)\n",
        "\n",
        "train_set = ProductLengthDataset(train_df, id_to_index, default_idx, mean, std)\n",
        "val_set   = ProductLengthDataset(val_df, id_to_index, default_idx, mean, std)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_set,   batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i4kt8d2k_2y"
      },
      "source": [
        "## Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF772A3ikkS_",
        "outputId": "31ce16c8-9409-4852-fec5-0d615a09e0b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 1500/1500 [1:42:13<00:00,  4.09s/it]\n",
            "Validation: 100%|██████████| 375/375 [05:19<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.0171955492099125\n",
            "Val MSE: 0.9230010840098063\n",
            "Val MAPE: 1.8599287\n",
            "Saved best model!\n",
            "\n",
            "Epoch 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 1500/1500 [1:41:54<00:00,  4.08s/it]\n",
            "Validation: 100%|██████████| 375/375 [05:11<00:00,  1.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.9446689146806796\n",
            "Val MSE: 0.9038403712908427\n",
            "Val MAPE: 1.9146003\n",
            "\n",
            "Epoch 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 1500/1500 [1:41:20<00:00,  4.05s/it]\n",
            "Validation: 100%|██████████| 375/375 [05:14<00:00,  1.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.9154600207805633\n",
            "Val MSE: 0.9029799310564994\n",
            "Val MAPE: 1.7654423\n",
            "Saved best model!\n"
          ]
        }
      ],
      "source": [
        "BACKBONE = \"bert-base-uncased\"\n",
        "model = TextCategoryRegressor(BACKBONE, len(id_to_index) + 1).to(DEVICE)\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "best_mape = 999\n",
        "for epoch in range(3):\n",
        "    print(f\"\\nEpoch {epoch+1}\")\n",
        "    tr_loss = train_epoch(model, train_loader, optim)\n",
        "    val_mse, val_mape = evaluate(model, val_loader, mean, std)\n",
        "\n",
        "    print(\"Train Loss:\", tr_loss)\n",
        "    print(\"Val MSE:\", val_mse)\n",
        "    print(\"Val MAPE:\", val_mape)\n",
        "\n",
        "    if val_mape < best_mape:\n",
        "        best_mape = val_mape\n",
        "        torch.save(model.state_dict(), \"best.pt\")\n",
        "        print(\"Saved best model!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N91m8BdlGSs"
      },
      "source": [
        "## Final Evaluation on the 20% Testing Set\n",
        "\n",
        "We now reload the best model (based on validation MAPE during training)\n",
        "and compute the final metrics on the held-out 20% validation split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCny5KnIlBxS",
        "outputId": "5612a234-5bc7-416e-b1f7-ba08c88900a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 375/375 [05:13<00:00,  1.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final evaluation on 20% validation split:\n",
            "MSE  (normalized target): 0.9029799310564994\n",
            "MAPE (original length):   1.7654423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load best model found during training\n",
        "model.load_state_dict(torch.load(\"best.pt\", map_location=DEVICE))\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "final_mse, final_mape = evaluate(model, val_loader, mean, std)\n",
        "\n",
        "print(\"Final evaluation on 20% validation split:\")\n",
        "print(\"MSE  (normalized target):\", final_mse)\n",
        "print(\"MAPE (original length):  \", final_mape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDsxByAb2V_x"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
